---
title: "Balancing AI Realism: Six Key Cues for Authentic Respitsonses"
date: 2024-08-03T00:50:30.730Z
updated: 2024-08-04T00:50:30.730Z
tags:
  - chatgpt
  - open-ai
categories:
  - openAI
  - chatgpt
description: "This Article Describes Balancing AI Realism: Six Key Cues for Authentic Respitsonses"
excerpt: "This Article Describes Balancing AI Realism: Six Key Cues for Authentic Respitsonses"
thumbnail: https://thmb.techidaily.com/56db2abce12454619eb56aa29719b3ba982081a7573c4ec93a0c358d91bb966c.jpg
---

## Balancing AI Realism: Six Key Cues for Authentic Respitsonses

### Key Takeaways

* Clear and specific prompts are crucial to minimize AI hallucination. Avoid vague instructions and provide explicit details to prevent unpredictable results.
* Use grounding or the "according to..." technique to attribute output to a specific source or perspective. This helps avoid factual errors and bias in AI-generated content.
* Use constraints and rules to shape AI output according to desired outcomes. Explicitly state constraints or imply them through context or task to prevent inappropriate or illogical outputs.

**MUO VIDEO OF THE DAY**

**SCROLL TO CONTINUE WITH CONTENT**

 Not getting the response you want from a generative AI model? You might be dealing with AI hallucination, a problem that occurs when the model produces inaccurate or irrelevant outputs.

 It is caused by various factors, such as the quality of the data used to train the model, a lack of context, or the ambiguity of the prompt. Fortunately, there are techniques you can use to get more reliable output from an AI model.

## 1\. Provide Clear and Specific Prompts

 The first step in [minimizing AI hallucination](http://www.makeuseof.com/prevent-ai-hallucination/) is to create clear and highly specific prompts. Vague or ambiguous prompts can lead to unpredictable results, as AI models may attempt to interpret the intent behind the prompt. Instead, be explicit in your instructions.

 Instead of asking, "Tell me about dogs," you could prompt, "Give me a detailed description of the physical characteristics and temperament of Golden Retrievers." Refining your prompt until it's clear is an easy way to prevent AI hallucination.

<!-- affiliate ads begin -->
<a href="https://unicoeye.pxf.io/c/5597632/2084399/18498" target="_top" id="2084399"><img src="//a.impactradius-go.com/display-ad/18498-2084399" border="0" alt="" width="1125" height="600"/></a><img height="0" width="0" src="https://imp.pxf.io/i/5597632/2084399/18498" style="position:absolute;visibility:hidden;" border="0" />
<!-- affiliate ads end -->
![screenshot of chatgpt response about golden retrievers](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2023/09/screenshot-of-chatgpt-response-about-golden-retrievers.JPG)

<!-- affiliate ads begin -->
<a href="https://secure.2checkout.com/order/checkout.php?PRODS=4665597&QTY=1&AFFILIATE=108875&CART=1"><img src="https://www.pcclean.io/wp-content/uploads/2018/03/winutilities-box-130521.png" border="0">WinUtilities Pro</a>
<!-- affiliate ads end -->
## 2\. Use Grounding or the "According to..." Technique

 One of the challenges of using AI systems is that they might generate outputs that are factually incorrect, biased, or inconsistent with your views or values. This can happen because the AI systems are trained on large and diverse datasets that might contain errors, opinions, or contradictions.

 To avoid this, you can use grounding or the "according to..." technique, which involves attributing the output to a specific source or perspective. For example, you could ask the AI system to write a fact about a topic according to Wikipedia, Google Scholar, or a specific publicly accessible source.

![screenshot of peace definition on bing ai](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2023/09/screenshot-of-peace-definition-on-bing-ai.JPG)

## 3\. Use Constraints and Rules

 Constraints and rules can help prevent the AI system from generating inappropriate, inconsistent, contradictory, or illogical outputs. They can also help shape and refine the output according to the desired outcome and purpose. Constraints and rules can be explicitly stated in the prompt or implicitly implied by the context or the task.

 Suppose you want to use an AI tool to write a poem about love. Instead of giving it a general prompt like "write a poem about love," you can give it a more constrained and rule-based prompt like "write a sonnet about love with 14 lines and 10 syllables per line."

![screenshot of poem generated by bard](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2023/09/screenshot-of-poem-generated-by-bard.JPG)

<!-- affiliate ads begin -->
<a href="https://purchase.swifdoo.com/order/checkout.php?PRODS=40002162&QTY=1&AFFILIATE=108875&CART=1"><img src="https://secure.avangate.com/images/merchant/8b932759a5a04ddb34bf79e3f9072e4b/products/1_Product%20box%20white-1024x1024.png" border="0">SwifDoo PDF Perpetual (1 PC) Free upgrade.Â No monthly fees ever. 
</a>
<!-- affiliate ads end -->
## 4\. Use Multi-Step Prompting

 Sometimes, complex questions can lead to AI hallucinations because the model attempts to answer them in a single step. To overcome this, break down your queries into multiple steps.

 For instance, instead of asking, "What is the most effective diabetes treatment?" you can ask, "What are the common treatments for diabetes?" You can then follow up with, "Which of these treatments is considered the most effective according to medical studies?"

 Multi-step prompting forces the AI model to provide intermediate information before arriving at a final answer, which can lead to more accurate and well-informed responses.

<!-- affiliate ads begin -->
<a href="https://secure.2checkout.com/order/checkout.php?PRODS=4620778&QTY=1&AFFILIATE=108875&CART=1"><img src="https://secure.avangate.com/images/merchant/07dd4d5a72f5740ef0f035f201951476/300__250banner.jpg" border="0"></a>
<!-- affiliate ads end -->
## 5\. Assign Role to AI

 When you assign a specific role to the AI model in your prompt, you clarify its purpose and reduce the likelihood of hallucination. For example, instead of saying, "Tell me about the history of quantum mechanics," you can prompt the AI with, "Assume the role of a diligent researcher and provide a summary of the key milestones in the history of quantum mechanics."

![screenshot of chatgpt response after role assignment](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2023/09/screenshot-of-chatgpt-response-after-role-assignment.JPG)

 This framing encourages the AI to act as a diligent researcher rather than a speculative storyteller.

## 6\. Add Contextual Information

 Not providing contextual information when necessary is a [prompt mistake to avoid when using ChatGPT](https://www.makeuseof.com/chatgpt-prompt-mistakes-to-avoid/) or other AI models. Contextual information helps the model understand the task's background, domain, or purpose and generate more relevant and coherent outputs. Contextual information includes keywords, tags, categories, examples, references, and sources.

 For example, if you want to generate a product review for a pair of headphones, you can provide contextual information, such as the product name, brand, features, price, rating, or customer feedback. A good prompt for this task could look something like this:

<!-- affiliate ads begin -->
<a href="https://vapordna.pxf.io/c/5597632/1496243/17238" target="_top" id="1496243"><img src="//a.impactradius-go.com/display-ad/17238-1496243" border="0" alt="" width="1000" height="1221"/></a><img height="0" width="0" src="https://imp.pxf.io/i/5597632/1496243/17238" style="position:absolute;visibility:hidden;" border="0" />
<!-- affiliate ads end -->
![screenshot of review generated by bard](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2023/09/screenshot-of-review-generated-by-bard.JPG)

<!-- affiliate ads begin -->
<a href="https://appsumo.8odi.net/c/5597632/2082532/7443" target="_top" id="2082532"><img src="//a.impactradius-go.com/display-ad/7443-2082532" border="0" alt="" width="1200" height="600"/></a><img height="0" width="0" src="https://appsumo.8odi.net/i/5597632/2082532/7443" style="position:absolute;visibility:hidden;" border="0" />
<!-- affiliate ads end -->
## Getting Better AI Responses

 It can be frustrating when you don't get the feedback you expect from an AI model. However, using these AI prompting techniques, you can reduce the likelihood of AI hallucination and get better and more reliable responses from your AI systems.

 Keep in mind that these techniques are not foolproof and may not work for every task or topic. You should always check and verify the AI outputs before using them for any serious purpose.

**MUO VIDEO OF THE DAY**

**SCROLL TO CONTINUE WITH CONTENT**

 Not getting the response you want from a generative AI model? You might be dealing with AI hallucination, a problem that occurs when the model produces inaccurate or irrelevant outputs.

 It is caused by various factors, such as the quality of the data used to train the model, a lack of context, or the ambiguity of the prompt. Fortunately, there are techniques you can use to get more reliable output from an AI model.

## 1\. Provide Clear and Specific Prompts

 The first step in [minimizing AI hallucination](http://www.makeuseof.com/prevent-ai-hallucination/) is to create clear and highly specific prompts. Vague or ambiguous prompts can lead to unpredictable results, as AI models may attempt to interpret the intent behind the prompt. Instead, be explicit in your instructions.

 Instead of asking, "Tell me about dogs," you could prompt, "Give me a detailed description of the physical characteristics and temperament of Golden Retrievers." Refining your prompt until it's clear is an easy way to prevent AI hallucination.

<!-- affiliate ads begin -->
<a href="https://estore.winxdvd.com/order/checkout.php?PRODS=1412049&QTY=1&AFFILIATE=108875&CART=1"><img src="https://www.winxdvd.com/affiliate/new-banner/pt-200x200.jpg" border="0"></a>
<!-- affiliate ads end -->
![screenshot of chatgpt response about golden retrievers](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2023/09/screenshot-of-chatgpt-response-about-golden-retrievers.JPG)

<!-- affiliate ads begin -->
<a href="https://shop.manycam.com/order/checkout.php?PRODS=17727588&QTY=1&AFFILIATE=108875&CART=1"><img src="https://secure.avangate.com/images/merchant/8230bea7d54bcdf99cdfe85cb07313d5/mcaffbanner600x500.png" border="0"></a>
<a href="https://shop.manycam.com/order/checkout.php?PRODS=17727588&QTY=1&AFFILIATE=108875&CART=1"><img src="https://secure.avangate.com/images/merchant/8230bea7d54bcdf99cdfe85cb07313d5/Affiliates_300x250px_valentinesday.png" border="0"></a>
<!-- affiliate ads end -->
## 2\. Use Grounding or the "According to..." Technique

 One of the challenges of using AI systems is that they might generate outputs that are factually incorrect, biased, or inconsistent with your views or values. This can happen because the AI systems are trained on large and diverse datasets that might contain errors, opinions, or contradictions.

 To avoid this, you can use grounding or the "according to..." technique, which involves attributing the output to a specific source or perspective. For example, you could ask the AI system to write a fact about a topic according to Wikipedia, Google Scholar, or a specific publicly accessible source.

![screenshot of peace definition on bing ai](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2023/09/screenshot-of-peace-definition-on-bing-ai.JPG)

<!-- affiliate ads begin -->
<a href="https://boody-eco-wear.pxf.io/c/5597632/1567905/13846" target="_top" id="1567905"><img src="//a.impactradius-go.com/display-ad/13846-1567905" border="0" alt="" width="300" height="250"/></a><img height="0" width="0" src="https://imp.pxf.io/i/5597632/1567905/13846" style="position:absolute;visibility:hidden;" border="0" />
<!-- affiliate ads end -->
## 3\. Use Constraints and Rules

 Constraints and rules can help prevent the AI system from generating inappropriate, inconsistent, contradictory, or illogical outputs. They can also help shape and refine the output according to the desired outcome and purpose. Constraints and rules can be explicitly stated in the prompt or implicitly implied by the context or the task.

 Suppose you want to use an AI tool to write a poem about love. Instead of giving it a general prompt like "write a poem about love," you can give it a more constrained and rule-based prompt like "write a sonnet about love with 14 lines and 10 syllables per line."

![screenshot of poem generated by bard](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2023/09/screenshot-of-poem-generated-by-bard.JPG)

<!-- affiliate ads begin -->
<a href="https://tinyland.pxf.io/c/5597632/1793214/19135" target="_top" id="1793214"><img src="//a.impactradius-go.com/display-ad/19135-1793214" border="0" alt="" width="900" height="900"/></a><img height="0" width="0" src="https://imp.pxf.io/i/5597632/1793214/19135" style="position:absolute;visibility:hidden;" border="0" />
<!-- affiliate ads end -->
## 4\. Use Multi-Step Prompting

 Sometimes, complex questions can lead to AI hallucinations because the model attempts to answer them in a single step. To overcome this, break down your queries into multiple steps.

 For instance, instead of asking, "What is the most effective diabetes treatment?" you can ask, "What are the common treatments for diabetes?" You can then follow up with, "Which of these treatments is considered the most effective according to medical studies?"

 Multi-step prompting forces the AI model to provide intermediate information before arriving at a final answer, which can lead to more accurate and well-informed responses.

## 5\. Assign Role to AI

 When you assign a specific role to the AI model in your prompt, you clarify its purpose and reduce the likelihood of hallucination. For example, instead of saying, "Tell me about the history of quantum mechanics," you can prompt the AI with, "Assume the role of a diligent researcher and provide a summary of the key milestones in the history of quantum mechanics."

![screenshot of chatgpt response after role assignment](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2023/09/screenshot-of-chatgpt-response-after-role-assignment.JPG)

 This framing encourages the AI to act as a diligent researcher rather than a speculative storyteller.

<!-- affiliate ads begin -->
<a href="https://secure.2checkout.com/order/checkout.php?PRODS=4721564&QTY=1&AFFILIATE=108875&CART=1"><img src="https://secure.avangate.com/images/merchant/c14a8df1e1b4d5297e9cb30cb34d5a00/products/copy_power-tools-48.png" border="0">Power Tools add-on for Google Sheets, 12-month subscription</a>
<!-- affiliate ads end -->
## 6\. Add Contextual Information

 Not providing contextual information when necessary is a [prompt mistake to avoid when using ChatGPT](https://www.makeuseof.com/chatgpt-prompt-mistakes-to-avoid/) or other AI models. Contextual information helps the model understand the task's background, domain, or purpose and generate more relevant and coherent outputs. Contextual information includes keywords, tags, categories, examples, references, and sources.

 For example, if you want to generate a product review for a pair of headphones, you can provide contextual information, such as the product name, brand, features, price, rating, or customer feedback. A good prompt for this task could look something like this:

<!-- affiliate ads begin -->
<a href="https://store.massmailsoftware.com/order/checkout.php?PRODS=1300375&QTY=1&AFFILIATE=108875&CART=1"><img src="https://secure.avangate.com/images/merchant/dc87c13749315c7217cdc4ac692e704c/banera_for_partners-15_%281%29.jpg" border="0"></a>
<!-- affiliate ads end -->
![screenshot of review generated by bard](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2023/09/screenshot-of-review-generated-by-bard.JPG)

## Getting Better AI Responses

 It can be frustrating when you don't get the feedback you expect from an AI model. However, using these AI prompting techniques, you can reduce the likelihood of AI hallucination and get better and more reliable responses from your AI systems.

 Keep in mind that these techniques are not foolproof and may not work for every task or topic. You should always check and verify the AI outputs before using them for any serious purpose.

**MUO VIDEO OF THE DAY**

**SCROLL TO CONTINUE WITH CONTENT**

 Not getting the response you want from a generative AI model? You might be dealing with AI hallucination, a problem that occurs when the model produces inaccurate or irrelevant outputs.

 It is caused by various factors, such as the quality of the data used to train the model, a lack of context, or the ambiguity of the prompt. Fortunately, there are techniques you can use to get more reliable output from an AI model.

## 1\. Provide Clear and Specific Prompts

 The first step in [minimizing AI hallucination](http://www.makeuseof.com/prevent-ai-hallucination/) is to create clear and highly specific prompts. Vague or ambiguous prompts can lead to unpredictable results, as AI models may attempt to interpret the intent behind the prompt. Instead, be explicit in your instructions.

 Instead of asking, "Tell me about dogs," you could prompt, "Give me a detailed description of the physical characteristics and temperament of Golden Retrievers." Refining your prompt until it's clear is an easy way to prevent AI hallucination.

![screenshot of chatgpt response about golden retrievers](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2023/09/screenshot-of-chatgpt-response-about-golden-retrievers.JPG)

<!-- affiliate ads begin -->
<a href="https://secure.2checkout.com/order/checkout.php?PRODS=37701530&QTY=1&AFFILIATE=108875&CART=1"><img src="https://secure.avangate.com/images/merchant/6fe0c81e3f9438db11ebbfba6c5ce460/products/copy_cbLogo_with_text_blue.png" border="0">CalendarBudget - Monthly subscription membership to CalendarBudgetÂ via web browser or mobile app. Support included. </a>
<!-- affiliate ads end -->
## 2\. Use Grounding or the "According to..." Technique

 One of the challenges of using AI systems is that they might generate outputs that are factually incorrect, biased, or inconsistent with your views or values. This can happen because the AI systems are trained on large and diverse datasets that might contain errors, opinions, or contradictions.

 To avoid this, you can use grounding or the "according to..." technique, which involves attributing the output to a specific source or perspective. For example, you could ask the AI system to write a fact about a topic according to Wikipedia, Google Scholar, or a specific publicly accessible source.

<!-- affiliate ads begin -->
<a href="https://secure.2checkout.com/order/checkout.php?PRODS=4620780&QTY=1&AFFILIATE=108875&CART=1"><img src="https://secure.avangate.com/images/merchant/07dd4d5a72f5740ef0f035f201951476/728__90banner.jpg" border="0"></a>
<!-- affiliate ads end -->
![screenshot of peace definition on bing ai](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2023/09/screenshot-of-peace-definition-on-bing-ai.JPG)

## 3\. Use Constraints and Rules

 Constraints and rules can help prevent the AI system from generating inappropriate, inconsistent, contradictory, or illogical outputs. They can also help shape and refine the output according to the desired outcome and purpose. Constraints and rules can be explicitly stated in the prompt or implicitly implied by the context or the task.

 Suppose you want to use an AI tool to write a poem about love. Instead of giving it a general prompt like "write a poem about love," you can give it a more constrained and rule-based prompt like "write a sonnet about love with 14 lines and 10 syllables per line."

![screenshot of poem generated by bard](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2023/09/screenshot-of-poem-generated-by-bard.JPG)

## 4\. Use Multi-Step Prompting

 Sometimes, complex questions can lead to AI hallucinations because the model attempts to answer them in a single step. To overcome this, break down your queries into multiple steps.

 For instance, instead of asking, "What is the most effective diabetes treatment?" you can ask, "What are the common treatments for diabetes?" You can then follow up with, "Which of these treatments is considered the most effective according to medical studies?"

 Multi-step prompting forces the AI model to provide intermediate information before arriving at a final answer, which can lead to more accurate and well-informed responses.

<!-- affiliate ads begin -->
<a href="https://cowinaudio.pxf.io/c/5597632/1116855/13794" target="_top" id="1116855"><img src="//a.impactradius-go.com/display-ad/13794-1116855" border="0" alt="" width="767" height="285"/></a><img height="0" width="0" src="https://imp.pxf.io/i/5597632/1116855/13794" style="position:absolute;visibility:hidden;" border="0" />
<!-- affiliate ads end -->
## 5\. Assign Role to AI

 When you assign a specific role to the AI model in your prompt, you clarify its purpose and reduce the likelihood of hallucination. For example, instead of saying, "Tell me about the history of quantum mechanics," you can prompt the AI with, "Assume the role of a diligent researcher and provide a summary of the key milestones in the history of quantum mechanics."

![screenshot of chatgpt response after role assignment](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2023/09/screenshot-of-chatgpt-response-after-role-assignment.JPG)

 This framing encourages the AI to act as a diligent researcher rather than a speculative storyteller.

## 6\. Add Contextual Information

 Not providing contextual information when necessary is a [prompt mistake to avoid when using ChatGPT](https://www.makeuseof.com/chatgpt-prompt-mistakes-to-avoid/) or other AI models. Contextual information helps the model understand the task's background, domain, or purpose and generate more relevant and coherent outputs. Contextual information includes keywords, tags, categories, examples, references, and sources.

 For example, if you want to generate a product review for a pair of headphones, you can provide contextual information, such as the product name, brand, features, price, rating, or customer feedback. A good prompt for this task could look something like this:

<!-- affiliate ads begin -->
<a href="https://shop.pcdj.com/order/checkout.php?PRODS=4698824&QTY=1&AFFILIATE=108875&CART=1"> <img src="https://secure.avangate.com/images/merchant/47f4b6321e9fd8e8f7326a6adc1a7c1e/products/dex3pro-screenshot-homepage.png" border="0">PCDJ DEX 3 for Windows & MAC is the total entertainment DJ software solution, offering audio, video, and karaoke mixing ability. Automatic beat-sync, smart looping, 4 decks, DJ MIDI controller support, Karaoke Streaming and much more. 
DEX 3 meets the demands of todayâs versatile DJ, without compromise! 
DEX 3 (Audio, Video and Karaoke Mixing Software for Windows/MAC | 3 Activations and Free Updates)</a>
<!-- affiliate ads end -->
![screenshot of review generated by bard](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2023/09/screenshot-of-review-generated-by-bard.JPG)

## Getting Better AI Responses

 It can be frustrating when you don't get the feedback you expect from an AI model. However, using these AI prompting techniques, you can reduce the likelihood of AI hallucination and get better and more reliable responses from your AI systems.

 Keep in mind that these techniques are not foolproof and may not work for every task or topic. You should always check and verify the AI outputs before using them for any serious purpose.

**MUO VIDEO OF THE DAY**

**SCROLL TO CONTINUE WITH CONTENT**

 Not getting the response you want from a generative AI model? You might be dealing with AI hallucination, a problem that occurs when the model produces inaccurate or irrelevant outputs.

 It is caused by various factors, such as the quality of the data used to train the model, a lack of context, or the ambiguity of the prompt. Fortunately, there are techniques you can use to get more reliable output from an AI model.

<!-- affiliate ads begin -->
<a href="https://secure.2checkout.com/order/checkout.php?PRODS=4621764&QTY=1&AFFILIATE=108875&CART=1"><img src="https://www.x-mirage.com/x-mirage/img/page-home.jpg" border="0"></a>
<!-- affiliate ads end -->
## 1\. Provide Clear and Specific Prompts

 The first step in [minimizing AI hallucination](http://www.makeuseof.com/prevent-ai-hallucination/) is to create clear and highly specific prompts. Vague or ambiguous prompts can lead to unpredictable results, as AI models may attempt to interpret the intent behind the prompt. Instead, be explicit in your instructions.

 Instead of asking, "Tell me about dogs," you could prompt, "Give me a detailed description of the physical characteristics and temperament of Golden Retrievers." Refining your prompt until it's clear is an easy way to prevent AI hallucination.

<!-- affiliate ads begin -->
<a href="https://checkout.abbyy.com/order/checkout.php?PRODS=39254549&QTY=1&AFFILIATE=108875&CART=1"> <img src="https://secure.avangate.com/images/merchant/0e5fb5c76fca16adbee503c9aff393cd/products/8_FR-Badges-NEW-FR-Standard-16-WIN-200.png" border="0"> PDF application, powered by AI-based OCR, for unified workflows with both digital and scanned documents. </a>
<!-- affiliate ads end -->
![screenshot of chatgpt response about golden retrievers](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2023/09/screenshot-of-chatgpt-response-about-golden-retrievers.JPG)

## 2\. Use Grounding or the "According to..." Technique

 One of the challenges of using AI systems is that they might generate outputs that are factually incorrect, biased, or inconsistent with your views or values. This can happen because the AI systems are trained on large and diverse datasets that might contain errors, opinions, or contradictions.

 To avoid this, you can use grounding or the "according to..." technique, which involves attributing the output to a specific source or perspective. For example, you could ask the AI system to write a fact about a topic according to Wikipedia, Google Scholar, or a specific publicly accessible source.

![screenshot of peace definition on bing ai](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2023/09/screenshot-of-peace-definition-on-bing-ai.JPG)

## 3\. Use Constraints and Rules

 Constraints and rules can help prevent the AI system from generating inappropriate, inconsistent, contradictory, or illogical outputs. They can also help shape and refine the output according to the desired outcome and purpose. Constraints and rules can be explicitly stated in the prompt or implicitly implied by the context or the task.

 Suppose you want to use an AI tool to write a poem about love. Instead of giving it a general prompt like "write a poem about love," you can give it a more constrained and rule-based prompt like "write a sonnet about love with 14 lines and 10 syllables per line."

![screenshot of poem generated by bard](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2023/09/screenshot-of-poem-generated-by-bard.JPG)

<!-- affiliate ads begin -->
<a href="https://aidotcom.pxf.io/c/5597632/2086436/19576" target="_top" id="2086436"><img src="//a.impactradius-go.com/display-ad/19576-2086436" border="0" alt="" width="1500" height="400"/></a><img height="0" width="0" src="https://imp.pxf.io/i/5597632/2086436/19576" style="position:absolute;visibility:hidden;" border="0" />
<!-- affiliate ads end -->
## 4\. Use Multi-Step Prompting

 Sometimes, complex questions can lead to AI hallucinations because the model attempts to answer them in a single step. To overcome this, break down your queries into multiple steps.

 For instance, instead of asking, "What is the most effective diabetes treatment?" you can ask, "What are the common treatments for diabetes?" You can then follow up with, "Which of these treatments is considered the most effective according to medical studies?"

 Multi-step prompting forces the AI model to provide intermediate information before arriving at a final answer, which can lead to more accurate and well-informed responses.

## 5\. Assign Role to AI

 When you assign a specific role to the AI model in your prompt, you clarify its purpose and reduce the likelihood of hallucination. For example, instead of saying, "Tell me about the history of quantum mechanics," you can prompt the AI with, "Assume the role of a diligent researcher and provide a summary of the key milestones in the history of quantum mechanics."

![screenshot of chatgpt response after role assignment](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2023/09/screenshot-of-chatgpt-response-after-role-assignment.JPG)

 This framing encourages the AI to act as a diligent researcher rather than a speculative storyteller.

## 6\. Add Contextual Information

 Not providing contextual information when necessary is a [prompt mistake to avoid when using ChatGPT](https://www.makeuseof.com/chatgpt-prompt-mistakes-to-avoid/) or other AI models. Contextual information helps the model understand the task's background, domain, or purpose and generate more relevant and coherent outputs. Contextual information includes keywords, tags, categories, examples, references, and sources.

 For example, if you want to generate a product review for a pair of headphones, you can provide contextual information, such as the product name, brand, features, price, rating, or customer feedback. A good prompt for this task could look something like this:

![screenshot of review generated by bard](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2023/09/screenshot-of-review-generated-by-bard.JPG)

<!-- affiliate ads begin -->
<a href="https://thefitville.pxf.io/c/5597632/1526796/15852" target="_top" id="1526796"><img src="//a.impactradius-go.com/display-ad/15852-1526796" border="0" alt="" width="1200" height="628"/></a><img height="0" width="0" src="https://imp.pxf.io/i/5597632/1526796/15852" style="position:absolute;visibility:hidden;" border="0" />
<!-- affiliate ads end -->
## Getting Better AI Responses

 It can be frustrating when you don't get the feedback you expect from an AI model. However, using these AI prompting techniques, you can reduce the likelihood of AI hallucination and get better and more reliable responses from your AI systems.

 Keep in mind that these techniques are not foolproof and may not work for every task or topic. You should always check and verify the AI outputs before using them for any serious purpose.


<ins class="adsbygoogle"
     style="display:block"
     data-ad-format="autorelaxed"
     data-ad-client="ca-pub-7571918770474297"
     data-ad-slot="1223367746"></ins>



<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-7571918770474297"
     data-ad-slot="8358498916"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>




