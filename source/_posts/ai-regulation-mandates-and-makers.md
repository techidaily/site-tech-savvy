---
title: "AI Regulation: Mandates and Makers"
date: 2024-08-18T10:08:46.457Z
updated: 2024-08-19T10:08:46.457Z
tags:
  - chatgpt
  - open-ai
categories:
  - openAI
  - chatgpt
description: "This Article Describes AI Regulation: Mandates and Makers"
excerpt: "This Article Describes AI Regulation: Mandates and Makers"
thumbnail: https://thmb.techidaily.com/f5bde08083c297970b9e93f509911df9c27588c391ed27c568746499c49e24b7.jpg
---

## AI Regulation: Mandates and Makers

### Key Takeaways

* AI needs stricter monitoring, as cybersecurity vulnerabilities and privacy concerns continue to emerge.
* The government, tech companies, and end users all have a role to play in regulating AI, but each approach has its limitations.
* Media outlets, non-profit organizations, tech industry associations, academic institutions, and law enforcement agencies also contribute to the regulation of AI.

**MUO VIDEO OF THE DAY**

**SCROLL TO CONTINUE WITH CONTENT**

 The general public has differing views on AI—some believe machines will replace human workers altogether, while others claim AI is a fad. One thing everyone agrees on, however, is that AI needs stricter monitoring.

 Despite the importance of AI regulation, it has taken a back seat to training. Developers are so obsessed with building the next biggest AI model that they’re trading cybersecurity for rapid advancement. The question isn’t if AI needs regulation; it’s which governing body with adequate funding, human resources, and technological capacity will take the initiative.

 So, who should regulate AI?

## Government Bodies

![White Government Institution Building With High Stairs](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2023/10/government-institution-building.jpg)

 Various people, from consumers to [tech leaders, hope the government will regulate AI](https://www.makeuseof.com/what-global-tech-leaders-think-about-ai/). Publicly funded institutions have the resources to do so. Even Elon Musk and Sam Altman, two main drivers of the AI race, believe that some [privacy concerns surrounding AI](https://www.makeuseof.com/what-is-ai-what-dangers-does-artificial-intelligence-pose/) are too dangerous for governing bodies to overlook.

 The government should focus on protecting its constituents’ privacy and civil liberties if it takes over AI regulation. Cybercriminals keep finding ways to exploit AI systems in their schemes. Individuals not well-versed in AI might easily get fooled by synthesized voices, deepfake videos, and bot-operated online profiles.

 However, one major issue with the government regulating AI is that it might inadvertently stifle innovation. AI is a complex, evolving technology. Unless the officials overseeing deployment, development, and training guidelines understand how AI works, they might make premature, inefficient judgments.

## AI Developers, Tech Companies, and Laboratories

![Male and Female Researchers Training White Robot Arm](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2023/10/two-researchers-training-robot-arm.jpg)

 Considering the potential roadblocks that might arise from the government monitoring AI, many would rather have tech companies spearhead regulation. They believe developers should be responsible for the tech they release. Self-regulation enables them to drive innovation and focus on advancing these systems efficiently.

 Moreover, their in-depth understanding of AI will help them make fair, informed guidelines prioritizing user safety without compromising functionality. As with any technology, industry expertise streamlines monitoring. Assigning untrained officials to regulate technologies they barely understand might present more problems than benefits.

 Take the 2018 U.S. Senate hearing about Facebook’s data privacy laws as an example. In this report by [The Washington Post](https://www.washingtonpost.com/news/the-switch/wp/2018/04/10/transcript-of-mark-zuckerbergs-senate-hearing/), you’ll see that many lawmakers are confused with Facebook’s basic functions. So unless the U.S. Senate creates a sole department of tech specialists, they’re likely not qualified to regulate such an advanced, ever-changing system like AI.

 However, the main issue with tech companies regulating themselves is that shady corporations might abuse their power. With no intervening third party, they’re basically free to do whatever they want.

## End Users

![Using Mobile ChatGPT App and Placing it in Hand](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2023/10/mobile-chatgpt-app.jpg)

<!-- affiliate ads begin -->
<a href="https://secure.2checkout.com/order/checkout.php?PRODS=4709458&QTY=1&AFFILIATE=108875&CART=1"><img src="https://3d-kstudio.com/wp-content/uploads/2019/10/Project-Manager-version-3-1600x900-768x419.jpg" border="0">Project Manager - Asset Browser for 3Ds Max</a>
<!-- affiliate ads end -->
 Some fear that government and private entities will abuse AI systems. They’re unsure about granting a handful of governing bodies total control over such powerful technologies, especially since AI is still evolving. They might eventually fight over authority rather than work toward efficient regulation.

 To mitigate these risks, skeptics believe that end users deserve free rein to use AI models how they want. They say government bodies should only interfere when AI users break the law. It’s an ambitious goal, but it could technically be achieved if open-source AI developers dominated market shares.

 That said, this setup puts non-tech-savvy individuals at a disadvantage. Users are responsible for setting the restrictions within their systems—unfortunately, not everyone has the resources to do so.

 It’s also short-sighted to remove proprietary models from the market. The proliferation of [open-source AI models has several positive and negative impacts](https://www.makeuseof.com/positive-negative-impacts-open-source-ai-language-models/); for some, the cons outweigh the pros.

## Other Entities That Play a Role in the Regulation of AI

 Although major entities will spearhead the regulation of AI, there are bodies that play significant roles:

<!-- affiliate ads begin -->
<a href="https://aofit.pxf.io/c/5597632/1399701/16396" target="_top" id="1399701"><img src="//a.impactradius-go.com/display-ad/16396-1399701" border="0" alt="" width="960" height="300"/></a><img height="0" width="0" src="https://imp.pxf.io/i/5597632/1399701/16396" style="position:absolute;visibility:hidden;" border="0" />
<!-- affiliate ads end -->
### 1\. Media Outlets

![Media News Reporter Interviewing Person](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2023/10/media-news-reporter.jpg)

<!-- affiliate ads begin -->
<a href="https://homestyler.sjv.io/c/5597632/2044747/22993" target="_top" id="2044747"><img src="//a.impactradius-go.com/display-ad/22993-2044747" border="0" alt="" width="300" height="250"/></a><img height="0" width="0" src="https://imp.pxf.io/i/5597632/2044747/22993" style="position:absolute;visibility:hidden;" border="0" />
<!-- affiliate ads end -->
 Media outlets play a critical role in shaping the public’s perception of AI. They report industry developments, share new tools, bring awareness to the harmful uses of AI, and interview experts about relevant concerns.

 Most of the facts end users know about AI basically come from media outlets. Publishing false data, whether on purpose or not, will cause irreversible damage—you can’t underestimate how fast misinformation spreads.

### 2\. Non-Governmental Organizations

 Several non-profit organizations are centered around protecting AI users’ privacy and civil liberties. They educate the public through free resources, advocate for new policies, cooperate with government officials, and voice out overlooked concerns.

 The only issue with NPOs is they’re usually short on resources. Since they aren’t connected to the government, they rely on private solicitations and donations for day-to-day operations. Sadly, only a few organizations get adequate funding.

<!-- affiliate ads begin -->
<a href="https://secure.2checkout.com/order/checkout.php?PRODS=37100474&QTY=1&AFFILIATE=108875&CART=1"><img src="https://awario.com/images/pages/index/img-leads-1280@1x.avif" border="0"></a>
<!-- affiliate ads end -->
### 3\. Tech Industry Associations

 AI-focused tech industry associations can represent the public’s rights and interests. Like NPOs, they work with lawmakers, represent concerned individuals, advocate for fair policies, and bring awareness to specific issues.

 The difference, however, is that they often have ties to private companies. Their members still do solicitations, but they’ll usually get enough funding from their parent organizations as long as they deliver results.

<!-- affiliate ads begin -->
<a href="https://secure.2checkout.com/order/checkout.php?PRODS=4727541&QTY=1&AFFILIATE=108875&CART=1"><img src="https://secure.avangate.com/images/merchant/5f4f7141b65a730b4efb0e0d51f63e94/products/copy_copy_forexrobotronbox.gif" border="0">Forex Robotron Gold Package</a>
<!-- affiliate ads end -->
### 4\. Academic Institutions

![School University Large Classroom With Brown Tables and Chairs](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2023/10/school-university-large-classroom.jpg)

<!-- affiliate ads begin -->
<a href="https://store.nero.com/order/checkout.php?PRODS=22889392&QTY=1&AFFILIATE=108875&CART=1"><img src="http://webstatic.nero.com/nero2015-com-wAssets/img/affiliate/media/banner728-90eng.jpg" border="0"></a>
<!-- affiliate ads end -->
 Although AI comes with several risks, it is inherently neutral. All biases, privacy issues, security errors, and potential cybercrime activities stem from humans, so AI by itself isn’t something to fear.

 But very few already understand how modern AI models work. Misconceptions skew people’s perception of AI, perpetuating baseless fears like AI taking over humanity or stealing jobs.

 Academic institutions could fill these educational gaps through accessible resources. There aren’t too many scholarly works on modern LLMs and NLP systems yet. The public can use AI more responsibly and combat cybercrimes if they wholly understand how it works.

<!-- affiliate ads begin -->
<a href="https://appsumo.8odi.net/c/5597632/2075482/7443" target="_top" id="2075482"><img src="//a.impactradius-go.com/display-ad/7443-2075482" border="0" alt="" width="1200" height="600"/></a><img height="0" width="0" src="https://appsumo.8odi.net/i/5597632/2075482/7443" style="position:absolute;visibility:hidden;" border="0" />
<!-- affiliate ads end -->
### 5\. Law Enforcement Agencies

 Law enforcement agencies should expect to encounter more [AI-enabled cyberattacks](https://www.makeuseof.com/ways-ai-can-help-cybercriminals/). With the proliferation of generative models, crooks can quickly synthesize voices, generate deepfake images, scrape [personally identifiable information](https://www.makeuseof.com/what-is-personally-identifiable-information/) (PII), and even create entirely new personas.

 Most agencies aren’t equipped to handle these crimes. They should invest in new systems and train their officers on modern cybercrimes; otherwise, they’ll have trouble catching these crooks.

## The Future of AI Regulation

 Considering AI’s fast-paced nature, it’s unlikely for a single governing body to control it. Yes, tech leaders will hold more power than consumers, but various entities must cooperate to manage AI risks without impeding advancements. It’s best to set control measures now while artificial general intelligence (AGI) is still a distant goal.

 That said, AI regulation is just as distant as AGI. In the meantime, users must observe safety practices to combat AI-driven threats. Good habits like limiting the people you connect with online and securing your digital PII already go a long way.

**MUO VIDEO OF THE DAY**

**SCROLL TO CONTINUE WITH CONTENT**

 The general public has differing views on AI—some believe machines will replace human workers altogether, while others claim AI is a fad. One thing everyone agrees on, however, is that AI needs stricter monitoring.

 Despite the importance of AI regulation, it has taken a back seat to training. Developers are so obsessed with building the next biggest AI model that they’re trading cybersecurity for rapid advancement. The question isn’t if AI needs regulation; it’s which governing body with adequate funding, human resources, and technological capacity will take the initiative.

 So, who should regulate AI?

## Government Bodies

![White Government Institution Building With High Stairs](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2023/10/government-institution-building.jpg)

<!-- affiliate ads begin -->
<a href="https://estore.winxdvd.com/order/checkout.php?PRODS=12653853&QTY=1&AFFILIATE=108875&CART=1"><img src="https://secure.avangate.com/images/merchant/bcb41ccdc4363c6848a1d760f26c28a0/products/14_videoproc-converter-ai-box.png" border="0"></a>
<!-- affiliate ads end -->
 Various people, from consumers to [tech leaders, hope the government will regulate AI](https://www.makeuseof.com/what-global-tech-leaders-think-about-ai/). Publicly funded institutions have the resources to do so. Even Elon Musk and Sam Altman, two main drivers of the AI race, believe that some [privacy concerns surrounding AI](https://www.makeuseof.com/what-is-ai-what-dangers-does-artificial-intelligence-pose/) are too dangerous for governing bodies to overlook.

 The government should focus on protecting its constituents’ privacy and civil liberties if it takes over AI regulation. Cybercriminals keep finding ways to exploit AI systems in their schemes. Individuals not well-versed in AI might easily get fooled by synthesized voices, deepfake videos, and bot-operated online profiles.

 However, one major issue with the government regulating AI is that it might inadvertently stifle innovation. AI is a complex, evolving technology. Unless the officials overseeing deployment, development, and training guidelines understand how AI works, they might make premature, inefficient judgments.

<!-- affiliate ads begin -->
<a href="https://secure.2checkout.com/order/checkout.php?PRODS=4537546&QTY=1&AFFILIATE=108875&CART=1"><img src="https://secure.avangate.com/images/merchant/4b0a0290ad7df100b77e86839989a75e/products/7_copy_2_2_hdpro.png" border="0">HD Video Converter Factory Pro</a>
<!-- affiliate ads end -->
## AI Developers, Tech Companies, and Laboratories

![Male and Female Researchers Training White Robot Arm](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2023/10/two-researchers-training-robot-arm.jpg)

 Considering the potential roadblocks that might arise from the government monitoring AI, many would rather have tech companies spearhead regulation. They believe developers should be responsible for the tech they release. Self-regulation enables them to drive innovation and focus on advancing these systems efficiently.

 Moreover, their in-depth understanding of AI will help them make fair, informed guidelines prioritizing user safety without compromising functionality. As with any technology, industry expertise streamlines monitoring. Assigning untrained officials to regulate technologies they barely understand might present more problems than benefits.

 Take the 2018 U.S. Senate hearing about Facebook’s data privacy laws as an example. In this report by [The Washington Post](https://www.washingtonpost.com/news/the-switch/wp/2018/04/10/transcript-of-mark-zuckerbergs-senate-hearing/), you’ll see that many lawmakers are confused with Facebook’s basic functions. So unless the U.S. Senate creates a sole department of tech specialists, they’re likely not qualified to regulate such an advanced, ever-changing system like AI.

 However, the main issue with tech companies regulating themselves is that shady corporations might abuse their power. With no intervening third party, they’re basically free to do whatever they want.

## End Users

![Using Mobile ChatGPT App and Placing it in Hand](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2023/10/mobile-chatgpt-app.jpg)

<!-- affiliate ads begin -->
<a href="https://secure.2checkout.com/order/checkout.php?PRODS=4940312&QTY=1&AFFILIATE=108875&CART=1"><img src="https://secure.avangate.com/images/merchant/333ac5d90817d69113471fbb6e531bee/sps-partnership-728x90eng.png" border="0"></a>
<!-- affiliate ads end -->
 Some fear that government and private entities will abuse AI systems. They’re unsure about granting a handful of governing bodies total control over such powerful technologies, especially since AI is still evolving. They might eventually fight over authority rather than work toward efficient regulation.

 To mitigate these risks, skeptics believe that end users deserve free rein to use AI models how they want. They say government bodies should only interfere when AI users break the law. It’s an ambitious goal, but it could technically be achieved if open-source AI developers dominated market shares.

 That said, this setup puts non-tech-savvy individuals at a disadvantage. Users are responsible for setting the restrictions within their systems—unfortunately, not everyone has the resources to do so.

 It’s also short-sighted to remove proprietary models from the market. The proliferation of [open-source AI models has several positive and negative impacts](https://www.makeuseof.com/positive-negative-impacts-open-source-ai-language-models/); for some, the cons outweigh the pros.

## Other Entities That Play a Role in the Regulation of AI

 Although major entities will spearhead the regulation of AI, there are bodies that play significant roles:

### 1\. Media Outlets

![Media News Reporter Interviewing Person](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2023/10/media-news-reporter.jpg)

<!-- affiliate ads begin -->
<a href="https://caperobbin.sjv.io/c/5597632/2006123/18460" target="_top" id="2006123"><img src="//a.impactradius-go.com/display-ad/18460-2006123" border="0" alt="" width="300" height="250"/></a><img height="0" width="0" src="https://imp.pxf.io/i/5597632/2006123/18460" style="position:absolute;visibility:hidden;" border="0" />
<!-- affiliate ads end -->
 Media outlets play a critical role in shaping the public’s perception of AI. They report industry developments, share new tools, bring awareness to the harmful uses of AI, and interview experts about relevant concerns.

 Most of the facts end users know about AI basically come from media outlets. Publishing false data, whether on purpose or not, will cause irreversible damage—you can’t underestimate how fast misinformation spreads.

### 2\. Non-Governmental Organizations

 Several non-profit organizations are centered around protecting AI users’ privacy and civil liberties. They educate the public through free resources, advocate for new policies, cooperate with government officials, and voice out overlooked concerns.

 The only issue with NPOs is they’re usually short on resources. Since they aren’t connected to the government, they rely on private solicitations and donations for day-to-day operations. Sadly, only a few organizations get adequate funding.

<!-- affiliate ads begin -->
<a href="https://shop.incomedia.eu/order/checkout.php?PRODS=39655089&QTY=1&AFFILIATE=108875&CART=1"><img src="https://incomedia.eu/files/images/affiliates/wa/01_WA_728x90.jpg" border="0"></a>
<!-- affiliate ads end -->
### 3\. Tech Industry Associations

 AI-focused tech industry associations can represent the public’s rights and interests. Like NPOs, they work with lawmakers, represent concerned individuals, advocate for fair policies, and bring awareness to specific issues.

 The difference, however, is that they often have ties to private companies. Their members still do solicitations, but they’ll usually get enough funding from their parent organizations as long as they deliver results.

### 4\. Academic Institutions

![School University Large Classroom With Brown Tables and Chairs](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2023/10/school-university-large-classroom.jpg)

<!-- affiliate ads begin -->
<a href="https://coinrule.sjv.io/c/5597632/1958379/18409" target="_top" id="1958379"><img src="//a.impactradius-go.com/display-ad/18409-1958379" border="0" alt="" width="856" height="508"/></a><img height="0" width="0" src="https://imp.pxf.io/i/5597632/1958379/18409" style="position:absolute;visibility:hidden;" border="0" />
<!-- affiliate ads end -->
 Although AI comes with several risks, it is inherently neutral. All biases, privacy issues, security errors, and potential cybercrime activities stem from humans, so AI by itself isn’t something to fear.

 But very few already understand how modern AI models work. Misconceptions skew people’s perception of AI, perpetuating baseless fears like AI taking over humanity or stealing jobs.

 Academic institutions could fill these educational gaps through accessible resources. There aren’t too many scholarly works on modern LLMs and NLP systems yet. The public can use AI more responsibly and combat cybercrimes if they wholly understand how it works.

### 5\. Law Enforcement Agencies

 Law enforcement agencies should expect to encounter more [AI-enabled cyberattacks](https://www.makeuseof.com/ways-ai-can-help-cybercriminals/). With the proliferation of generative models, crooks can quickly synthesize voices, generate deepfake images, scrape [personally identifiable information](https://www.makeuseof.com/what-is-personally-identifiable-information/) (PII), and even create entirely new personas.

 Most agencies aren’t equipped to handle these crimes. They should invest in new systems and train their officers on modern cybercrimes; otherwise, they’ll have trouble catching these crooks.

## The Future of AI Regulation

 Considering AI’s fast-paced nature, it’s unlikely for a single governing body to control it. Yes, tech leaders will hold more power than consumers, but various entities must cooperate to manage AI risks without impeding advancements. It’s best to set control measures now while artificial general intelligence (AGI) is still a distant goal.

 That said, AI regulation is just as distant as AGI. In the meantime, users must observe safety practices to combat AI-driven threats. Good habits like limiting the people you connect with online and securing your digital PII already go a long way.

**MUO VIDEO OF THE DAY**

**SCROLL TO CONTINUE WITH CONTENT**

 The general public has differing views on AI—some believe machines will replace human workers altogether, while others claim AI is a fad. One thing everyone agrees on, however, is that AI needs stricter monitoring.

 Despite the importance of AI regulation, it has taken a back seat to training. Developers are so obsessed with building the next biggest AI model that they’re trading cybersecurity for rapid advancement. The question isn’t if AI needs regulation; it’s which governing body with adequate funding, human resources, and technological capacity will take the initiative.

 So, who should regulate AI?

<!-- affiliate ads begin -->
<a href="https://appsumo.8odi.net/c/5597632/2068407/7443" target="_top" id="2068407"><img src="//a.impactradius-go.com/display-ad/7443-2068407" border="0" alt="" width="1200" height="600"/></a><img height="0" width="0" src="https://appsumo.8odi.net/i/5597632/2068407/7443" style="position:absolute;visibility:hidden;" border="0" />
<!-- affiliate ads end -->
## Government Bodies

![White Government Institution Building With High Stairs](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2023/10/government-institution-building.jpg)

 Various people, from consumers to [tech leaders, hope the government will regulate AI](https://www.makeuseof.com/what-global-tech-leaders-think-about-ai/). Publicly funded institutions have the resources to do so. Even Elon Musk and Sam Altman, two main drivers of the AI race, believe that some [privacy concerns surrounding AI](https://www.makeuseof.com/what-is-ai-what-dangers-does-artificial-intelligence-pose/) are too dangerous for governing bodies to overlook.

 The government should focus on protecting its constituents’ privacy and civil liberties if it takes over AI regulation. Cybercriminals keep finding ways to exploit AI systems in their schemes. Individuals not well-versed in AI might easily get fooled by synthesized voices, deepfake videos, and bot-operated online profiles.

 However, one major issue with the government regulating AI is that it might inadvertently stifle innovation. AI is a complex, evolving technology. Unless the officials overseeing deployment, development, and training guidelines understand how AI works, they might make premature, inefficient judgments.

<!-- affiliate ads begin -->
<a href="https://secure.2checkout.com/order/checkout.php?PRODS=4621764&QTY=1&AFFILIATE=108875&CART=1"><img src="https://www.x-mirage.com/x-mirage/img/page-home.jpg" border="0"></a>
<!-- affiliate ads end -->
## AI Developers, Tech Companies, and Laboratories

![Male and Female Researchers Training White Robot Arm](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2023/10/two-researchers-training-robot-arm.jpg)

<!-- affiliate ads begin -->
<a href="https://secure.2checkout.com/order/checkout.php?PRODS=4620778&QTY=1&AFFILIATE=108875&CART=1"><img src="https://secure.avangate.com/images/merchant/07dd4d5a72f5740ef0f035f201951476/728__90banner.jpg" border="0"></a>
<!-- affiliate ads end -->
 Considering the potential roadblocks that might arise from the government monitoring AI, many would rather have tech companies spearhead regulation. They believe developers should be responsible for the tech they release. Self-regulation enables them to drive innovation and focus on advancing these systems efficiently.

 Moreover, their in-depth understanding of AI will help them make fair, informed guidelines prioritizing user safety without compromising functionality. As with any technology, industry expertise streamlines monitoring. Assigning untrained officials to regulate technologies they barely understand might present more problems than benefits.

 Take the 2018 U.S. Senate hearing about Facebook’s data privacy laws as an example. In this report by [The Washington Post](https://www.washingtonpost.com/news/the-switch/wp/2018/04/10/transcript-of-mark-zuckerbergs-senate-hearing/), you’ll see that many lawmakers are confused with Facebook’s basic functions. So unless the U.S. Senate creates a sole department of tech specialists, they’re likely not qualified to regulate such an advanced, ever-changing system like AI.

 However, the main issue with tech companies regulating themselves is that shady corporations might abuse their power. With no intervening third party, they’re basically free to do whatever they want.

## End Users

![Using Mobile ChatGPT App and Placing it in Hand](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2023/10/mobile-chatgpt-app.jpg)

<!-- affiliate ads begin -->
<a href="https://estore.macxdvd.com/order/checkout.php?PRODS=4526659&QTY=1&AFFILIATE=108875&CART=1"><img src="https://www.macxdvd.com/affiliate/new-banner/vcp-500x500.jpg" border="0"></a>
<!-- affiliate ads end -->
 Some fear that government and private entities will abuse AI systems. They’re unsure about granting a handful of governing bodies total control over such powerful technologies, especially since AI is still evolving. They might eventually fight over authority rather than work toward efficient regulation.

 To mitigate these risks, skeptics believe that end users deserve free rein to use AI models how they want. They say government bodies should only interfere when AI users break the law. It’s an ambitious goal, but it could technically be achieved if open-source AI developers dominated market shares.

 That said, this setup puts non-tech-savvy individuals at a disadvantage. Users are responsible for setting the restrictions within their systems—unfortunately, not everyone has the resources to do so.

 It’s also short-sighted to remove proprietary models from the market. The proliferation of [open-source AI models has several positive and negative impacts](https://www.makeuseof.com/positive-negative-impacts-open-source-ai-language-models/); for some, the cons outweigh the pros.

## Other Entities That Play a Role in the Regulation of AI

 Although major entities will spearhead the regulation of AI, there are bodies that play significant roles:

### 1\. Media Outlets

![Media News Reporter Interviewing Person](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2023/10/media-news-reporter.jpg)

 Media outlets play a critical role in shaping the public’s perception of AI. They report industry developments, share new tools, bring awareness to the harmful uses of AI, and interview experts about relevant concerns.

 Most of the facts end users know about AI basically come from media outlets. Publishing false data, whether on purpose or not, will cause irreversible damage—you can’t underestimate how fast misinformation spreads.

### 2\. Non-Governmental Organizations

 Several non-profit organizations are centered around protecting AI users’ privacy and civil liberties. They educate the public through free resources, advocate for new policies, cooperate with government officials, and voice out overlooked concerns.

 The only issue with NPOs is they’re usually short on resources. Since they aren’t connected to the government, they rely on private solicitations and donations for day-to-day operations. Sadly, only a few organizations get adequate funding.

<!-- affiliate ads begin -->
<a href="https://printrendy.pxf.io/c/5597632/1453719/17020" target="_top" id="1453719"><img src="//a.impactradius-go.com/display-ad/17020-1453719" border="0" alt="" width="300" height="250"/></a><img height="0" width="0" src="https://imp.pxf.io/i/5597632/1453719/17020" style="position:absolute;visibility:hidden;" border="0" />
<!-- affiliate ads end -->
### 3\. Tech Industry Associations

 AI-focused tech industry associations can represent the public’s rights and interests. Like NPOs, they work with lawmakers, represent concerned individuals, advocate for fair policies, and bring awareness to specific issues.

 The difference, however, is that they often have ties to private companies. Their members still do solicitations, but they’ll usually get enough funding from their parent organizations as long as they deliver results.

<!-- affiliate ads begin -->
<a href="https://store.nero.com/order/checkout.php?PRODS=39694080&QTY=1&AFFILIATE=108875&CART=1"><img src="http://cdnwww.nero.com/nero-com-wAssets/img/banners/2023/nbr/fire/Screenshot_1red_gb.jpg" border="0">Nero Burning ROM:
The ultimate burning program for all your needs!</a>
<!-- affiliate ads end -->
### 4\. Academic Institutions

![School University Large Classroom With Brown Tables and Chairs](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2023/10/school-university-large-classroom.jpg)

<!-- affiliate ads begin -->
<a href="https://appsumo.8odi.net/c/5597632/2068425/7443" target="_top" id="2068425"><img src="//a.impactradius-go.com/display-ad/7443-2068425" border="0" alt="" width="1200" height="600"/></a><img height="0" width="0" src="https://appsumo.8odi.net/i/5597632/2068425/7443" style="position:absolute;visibility:hidden;" border="0" />
<!-- affiliate ads end -->
 Although AI comes with several risks, it is inherently neutral. All biases, privacy issues, security errors, and potential cybercrime activities stem from humans, so AI by itself isn’t something to fear.

 But very few already understand how modern AI models work. Misconceptions skew people’s perception of AI, perpetuating baseless fears like AI taking over humanity or stealing jobs.

 Academic institutions could fill these educational gaps through accessible resources. There aren’t too many scholarly works on modern LLMs and NLP systems yet. The public can use AI more responsibly and combat cybercrimes if they wholly understand how it works.

### 5\. Law Enforcement Agencies

 Law enforcement agencies should expect to encounter more [AI-enabled cyberattacks](https://www.makeuseof.com/ways-ai-can-help-cybercriminals/). With the proliferation of generative models, crooks can quickly synthesize voices, generate deepfake images, scrape [personally identifiable information](https://www.makeuseof.com/what-is-personally-identifiable-information/) (PII), and even create entirely new personas.

 Most agencies aren’t equipped to handle these crimes. They should invest in new systems and train their officers on modern cybercrimes; otherwise, they’ll have trouble catching these crooks.

## The Future of AI Regulation

 Considering AI’s fast-paced nature, it’s unlikely for a single governing body to control it. Yes, tech leaders will hold more power than consumers, but various entities must cooperate to manage AI risks without impeding advancements. It’s best to set control measures now while artificial general intelligence (AGI) is still a distant goal.

 That said, AI regulation is just as distant as AGI. In the meantime, users must observe safety practices to combat AI-driven threats. Good habits like limiting the people you connect with online and securing your digital PII already go a long way.

**MUO VIDEO OF THE DAY**

**SCROLL TO CONTINUE WITH CONTENT**

 The general public has differing views on AI—some believe machines will replace human workers altogether, while others claim AI is a fad. One thing everyone agrees on, however, is that AI needs stricter monitoring.

 Despite the importance of AI regulation, it has taken a back seat to training. Developers are so obsessed with building the next biggest AI model that they’re trading cybersecurity for rapid advancement. The question isn’t if AI needs regulation; it’s which governing body with adequate funding, human resources, and technological capacity will take the initiative.

 So, who should regulate AI?

## Government Bodies

![White Government Institution Building With High Stairs](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2023/10/government-institution-building.jpg)

<!-- affiliate ads begin -->
<a href="https://mindmanager.sjv.io/c/5597632/1787667/20231" target="_top" id="1787667"><img src="//a.impactradius-go.com/display-ad/20231-1787667" border="0" alt="" width="728" height="90"/></a><img height="0" width="0" src="https://imp.pxf.io/i/5597632/1787667/20231" style="position:absolute;visibility:hidden;" border="0" />
<!-- affiliate ads end -->
 Various people, from consumers to [tech leaders, hope the government will regulate AI](https://www.makeuseof.com/what-global-tech-leaders-think-about-ai/). Publicly funded institutions have the resources to do so. Even Elon Musk and Sam Altman, two main drivers of the AI race, believe that some [privacy concerns surrounding AI](https://www.makeuseof.com/what-is-ai-what-dangers-does-artificial-intelligence-pose/) are too dangerous for governing bodies to overlook.

 The government should focus on protecting its constituents’ privacy and civil liberties if it takes over AI regulation. Cybercriminals keep finding ways to exploit AI systems in their schemes. Individuals not well-versed in AI might easily get fooled by synthesized voices, deepfake videos, and bot-operated online profiles.

 However, one major issue with the government regulating AI is that it might inadvertently stifle innovation. AI is a complex, evolving technology. Unless the officials overseeing deployment, development, and training guidelines understand how AI works, they might make premature, inefficient judgments.

## AI Developers, Tech Companies, and Laboratories

![Male and Female Researchers Training White Robot Arm](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2023/10/two-researchers-training-robot-arm.jpg)

 Considering the potential roadblocks that might arise from the government monitoring AI, many would rather have tech companies spearhead regulation. They believe developers should be responsible for the tech they release. Self-regulation enables them to drive innovation and focus on advancing these systems efficiently.

 Moreover, their in-depth understanding of AI will help them make fair, informed guidelines prioritizing user safety without compromising functionality. As with any technology, industry expertise streamlines monitoring. Assigning untrained officials to regulate technologies they barely understand might present more problems than benefits.

 Take the 2018 U.S. Senate hearing about Facebook’s data privacy laws as an example. In this report by [The Washington Post](https://www.washingtonpost.com/news/the-switch/wp/2018/04/10/transcript-of-mark-zuckerbergs-senate-hearing/), you’ll see that many lawmakers are confused with Facebook’s basic functions. So unless the U.S. Senate creates a sole department of tech specialists, they’re likely not qualified to regulate such an advanced, ever-changing system like AI.

 However, the main issue with tech companies regulating themselves is that shady corporations might abuse their power. With no intervening third party, they’re basically free to do whatever they want.

<!-- affiliate ads begin -->
<a href="https://propmoneyinc.pxf.io/c/5597632/1803116/14559" target="_top" id="1803116"><img src="//a.impactradius-go.com/display-ad/14559-1803116" border="0" alt="" width="859" height="859"/></a><img height="0" width="0" src="https://imp.pxf.io/i/5597632/1803116/14559" style="position:absolute;visibility:hidden;" border="0" />
<!-- affiliate ads end -->
## End Users

![Using Mobile ChatGPT App and Placing it in Hand](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2023/10/mobile-chatgpt-app.jpg)

<!-- affiliate ads begin -->
<a href="https://lightailing.sjv.io/c/5597632/1725213/17190" target="_top" id="1725213"><img src="//a.impactradius-go.com/display-ad/17190-1725213" border="0" alt="" width="1000" height="1000"/></a><img height="0" width="0" src="https://imp.pxf.io/i/5597632/1725213/17190" style="position:absolute;visibility:hidden;" border="0" />
<!-- affiliate ads end -->
 Some fear that government and private entities will abuse AI systems. They’re unsure about granting a handful of governing bodies total control over such powerful technologies, especially since AI is still evolving. They might eventually fight over authority rather than work toward efficient regulation.

 To mitigate these risks, skeptics believe that end users deserve free rein to use AI models how they want. They say government bodies should only interfere when AI users break the law. It’s an ambitious goal, but it could technically be achieved if open-source AI developers dominated market shares.

 That said, this setup puts non-tech-savvy individuals at a disadvantage. Users are responsible for setting the restrictions within their systems—unfortunately, not everyone has the resources to do so.

 It’s also short-sighted to remove proprietary models from the market. The proliferation of [open-source AI models has several positive and negative impacts](https://www.makeuseof.com/positive-negative-impacts-open-source-ai-language-models/); for some, the cons outweigh the pros.

<!-- affiliate ads begin -->
<a href="https://secure.2checkout.com/order/checkout.php?PRODS=4715391&QTY=1&AFFILIATE=108875&CART=1"><img src="https://secure.avangate.com/images/merchant/7f687767ccf20fcea1c9dc4a5adc2326/Digisigner_banner_728_x_90_color_version.png" border="0"></a>
<!-- affiliate ads end -->
## Other Entities That Play a Role in the Regulation of AI

 Although major entities will spearhead the regulation of AI, there are bodies that play significant roles:

### 1\. Media Outlets

![Media News Reporter Interviewing Person](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2023/10/media-news-reporter.jpg)

<!-- affiliate ads begin -->
<a href="https://secure.2checkout.com/order/checkout.php?PRODS=37100474&QTY=1&AFFILIATE=108875&CART=1"><img src="https://awario.com/images/pages/index/img-platform-ui-1280@1x.avif" border="0"></a>
<!-- affiliate ads end -->
 Media outlets play a critical role in shaping the public’s perception of AI. They report industry developments, share new tools, bring awareness to the harmful uses of AI, and interview experts about relevant concerns.

 Most of the facts end users know about AI basically come from media outlets. Publishing false data, whether on purpose or not, will cause irreversible damage—you can’t underestimate how fast misinformation spreads.

### 2\. Non-Governmental Organizations

 Several non-profit organizations are centered around protecting AI users’ privacy and civil liberties. They educate the public through free resources, advocate for new policies, cooperate with government officials, and voice out overlooked concerns.

 The only issue with NPOs is they’re usually short on resources. Since they aren’t connected to the government, they rely on private solicitations and donations for day-to-day operations. Sadly, only a few organizations get adequate funding.

<!-- affiliate ads begin -->
<a href="https://secure.2checkout.com/order/checkout.php?PRODS=4729320&QTY=1&AFFILIATE=108875&CART=1"><img src="https://secure.avangate.com/images/merchant/f7f07e7dab09533bc71247a5b29a7373/products/2_iDeviceMessageBox.png" border="0"></a>
<!-- affiliate ads end -->
### 3\. Tech Industry Associations

 AI-focused tech industry associations can represent the public’s rights and interests. Like NPOs, they work with lawmakers, represent concerned individuals, advocate for fair policies, and bring awareness to specific issues.

 The difference, however, is that they often have ties to private companies. Their members still do solicitations, but they’ll usually get enough funding from their parent organizations as long as they deliver results.

<!-- affiliate ads begin -->
<a href="https://shop.mondly.com/affiliate.php?ACCOUNT=ATISTUDI&AFFILIATE=108875&PATH=https%3A%2F%2Fwww.mondly.com%3FAFFILIATE%3D108875%26RESOURCE%3D%2BGeneral%2B970x90%2B"><img src="https://secure.avangate.com/images/merchant/69c418c33ec2e1a4267fa9bb77fa1428/general-970x90.gif" border="0"></a>
<!-- affiliate ads end -->
### 4\. Academic Institutions

![School University Large Classroom With Brown Tables and Chairs](https://static1.makeuseofimages.com/wordpress/wp-content/uploads/2023/10/school-university-large-classroom.jpg)

 Although AI comes with several risks, it is inherently neutral. All biases, privacy issues, security errors, and potential cybercrime activities stem from humans, so AI by itself isn’t something to fear.

 But very few already understand how modern AI models work. Misconceptions skew people’s perception of AI, perpetuating baseless fears like AI taking over humanity or stealing jobs.

 Academic institutions could fill these educational gaps through accessible resources. There aren’t too many scholarly works on modern LLMs and NLP systems yet. The public can use AI more responsibly and combat cybercrimes if they wholly understand how it works.

### 5\. Law Enforcement Agencies

 Law enforcement agencies should expect to encounter more [AI-enabled cyberattacks](https://www.makeuseof.com/ways-ai-can-help-cybercriminals/). With the proliferation of generative models, crooks can quickly synthesize voices, generate deepfake images, scrape [personally identifiable information](https://www.makeuseof.com/what-is-personally-identifiable-information/) (PII), and even create entirely new personas.

 Most agencies aren’t equipped to handle these crimes. They should invest in new systems and train their officers on modern cybercrimes; otherwise, they’ll have trouble catching these crooks.

## The Future of AI Regulation

 Considering AI’s fast-paced nature, it’s unlikely for a single governing body to control it. Yes, tech leaders will hold more power than consumers, but various entities must cooperate to manage AI risks without impeding advancements. It’s best to set control measures now while artificial general intelligence (AGI) is still a distant goal.

 That said, AI regulation is just as distant as AGI. In the meantime, users must observe safety practices to combat AI-driven threats. Good habits like limiting the people you connect with online and securing your digital PII already go a long way.

<ins class="adsbygoogle"
     style="display:block"
     data-ad-format="autorelaxed"
     data-ad-client="ca-pub-7571918770474297"
     data-ad-slot="1223367746"></ins>



<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-7571918770474297"
     data-ad-slot="8358498916"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>

<span class="atpl-alsoreadstyle">Also read:</span>
<div><ul>
<li><a href="https://fox-blue.techidaily.com/new-2024-approved-exploring-periscopes-world-free-access-and-user-registration/"><u>[New] 2024 Approved  Exploring Periscope's World  Free Access & User Registration</u></a></li>
<li><a href="https://facebook-video-share.techidaily.com/new-elevate-engagement-enhancing-videos-with-pro-editing-skills-for-2024/"><u>[New] Elevate Engagement  Enhancing Videos with Pro Editing Skills for 2024</u></a></li>
<li><a href="https://video-capture.techidaily.com/new-expert-routines-for-flawless-webinar-replays-for-2024/"><u>[New] Expert Routines for Flawless Webinar Replays for 2024</u></a></li>
<li><a href="https://instagram-video-recordings.techidaily.com/new-ig-upgrade-starts-here-top-tools-for-follower-growth/"><u>[New] IG Upgrade Starts Here  Top Tools for Follower Growth</u></a></li>
<li><a href="https://screen-mirroring-recording.techidaily.com/new-mmo-universe-guidebook-best-10-free-roleplaying-games/"><u>[New] MMO Universe Guidebook  Best 10 Free Roleplaying Games</u></a></li>
<li><a href="https://facebook-video-content.techidaily.com/new-social-syncopation-the-rhythm-of-sharing-media-on-facebook/"><u>[New] Social Syncopation  The Rhythm of Sharing Media on Facebook</u></a></li>
<li><a href="https://twitter-videos.techidaily.com/new-unveiling-snapchat-video-feeds-from-twitter-for-2024/"><u>[New] Unveiling Snapchat Video Feeds From Twitter for 2024</u></a></li>
<li><a href="https://youtube-blog.techidaily.com/ed-2024-approved-step-by-step-on-streaming-google-meet-directly-to-youtube-channel/"><u>[Updated] 2024 Approved  Step by Step on Streaming Google Meet Directly to YouTube Channel</u></a></li>
<li><a href="https://facebook-video-share.techidaily.com/updated-in-2024-cutting-edge-content-creation-premier-android-editors/"><u>[Updated] In 2024, Cutting-Edge Content Creation  Premier Android Editors</u></a></li>
<li><a href="https://some-guidance.techidaily.com/updated-unlock-the-mystery-of-smooth-media-imports-into-windows-10/"><u>[Updated] Unlock the Mystery of Smooth Media Imports Into Windows 10</u></a></li>
<li><a href="https://facebook-video-share.techidaily.com/updated-unlocking-simplicity-your-guide-to-direct-signup-buttons/"><u>[Updated] Unlocking Simplicity  Your Guide to Direct Signup Buttons</u></a></li>
<li><a href="https://instagram-video-files.techidaily.com/2024-approved-imovie-techniques-for-squaring-up-your-instagram-feed/"><u>2024 Approved  IMovie Techniques for Squaring Up Your Instagram Feed</u></a></li>
<li><a href="https://screen-video-capture.techidaily.com/2024-approved-premier-webcam-selections-for-dynamic-twitch-sessions/"><u>2024 Approved  Premier Webcam Selections for Dynamic Twitch Sessions</u></a></li>
<li><a href="https://some-skills.techidaily.com/2024-approved-supreme-display-quality-top-10-ranking-of-4k-screens/"><u>2024 Approved  Supreme Display Quality  #Top 10 Ranking of 4K Screens</u></a></li>
<li><a href="https://android-location-track.techidaily.com/3-solutions-to-find-your-samsung-galaxy-m54-5g-current-location-of-a-mobile-number-drfone-by-drfone-virtual-android/"><u>3 Solutions to Find Your Samsung Galaxy M54 5G Current Location of a Mobile Number | Dr.fone</u></a></li>
<li><a href="https://tech-savvy.techidaily.com/are-there-size-constraints-on-gpt-3-responses/"><u>Are There Size Constraints on GPT-3 Responses?</u></a></li>
<li><a href="https://tech-savvy.techidaily.com/detective-your-way-join-4-virtual-ai-crime-solving-experiences/"><u>Detective Your Way: Join 4 Virtual AI Crime-Solving Experiences</u></a></li>
<li><a href="https://win-dash.techidaily.com/download-nvidias-new-geforce-rtx-3080-drivers-optimized-for-windows-versions-10-8-and-7/"><u>Download NVIDIA's New GeForce RTX 3080 Drivers - Optimized for Windows Versions 10, 8 & 7</u></a></li>
<li><a href="https://tech-savvy.techidaily.com/enhance-interaction-top-9-upgrade-tips-to-chatgptplus/"><u>Enhance Interaction: Top 9 Upgrade Tips to ChatGPT+</u></a></li>
<li><a href="https://tech-savvy.techidaily.com/gpt-pluss-challenge-to-ai-supremacy-with-perplexity/"><u>GPT Plus's Challenge to AI Supremacy with Perplexity</u></a></li>
<li><a href="https://tech-savvy.techidaily.com/gpts-role-in-streamlining-writers-workflow/"><u>GPT's Role in Streamlining Writers' Workflow</u></a></li>
<li><a href="https://tech-savvy.techidaily.com/how-ai-chatbots-learn-to-communicate-like-us/"><u>How AI Chatbots Learn to Communicate Like Us</u></a></li>
<li><a href="https://tech-savvy.techidaily.com/how-to-use-chatgpt-to-prevent-feelings-of-loneliness/"><u>How to Use ChatGPT to Prevent Feelings of Loneliness</u></a></li>
<li><a href="https://android-pokemon-go.techidaily.com/how-to-use-ispoofer-on-oneplus-ace-3-drfone-by-drfone-virtual-android/"><u>How to use iSpoofer on OnePlus Ace 3? | Dr.fone</u></a></li>
<li><a href="https://ios-unlock.techidaily.com/in-2024-forgot-locked-apple-iphone-se-password-learn-the-best-methods-to-unlock-by-drfone-ios/"><u>In 2024, Forgot Locked Apple iPhone SE Password? Learn the Best Methods To Unlock</u></a></li>
<li><a href="https://tech-savvy.techidaily.com/inside-mechanics-of-7-apps-boosted-by-gpt-4-technology/"><u>Inside Mechanics of 7 Apps Boosted by GPT-4 Technology</u></a></li>
<li><a href="https://tech-savvy.techidaily.com/launch-a-cost-free-windows-gpt-simulator-with-gpt4all/"><u>Launch a Cost-Free Windows GPT Simulator with GPT4All</u></a></li>
<li><a href="https://tech-savvy.techidaily.com/launching-liberated-chatgpt-on-windows/"><u>Launching Liberated ChatGPT on Windows</u></a></li>
<li><a href="https://tech-savvy.techidaily.com/leverage-ai-to-transform-how-you-handle-pdfs-quickly/"><u>Leverage AI to Transform How You Handle PDFs Quickly</u></a></li>
<li><a href="https://tech-savvy.techidaily.com/mastering-chatgpt-4-techniques-for-reading-pdfs/"><u>Mastering ChatGPT: 4 Techniques for Reading PDFs</u></a></li>
<li><a href="https://tech-savvy.techidaily.com/navigating-multilingualism-with-chatgpt-premium-tools/"><u>Navigating Multilingualism with ChatGPT Premium Tools</u></a></li>
<li><a href="https://tech-savvy.techidaily.com/next-gen-ai-disrupting-home-craftsmanship/"><u>Next-Gen AI Disrupting Home Craftsmanship</u></a></li>
<li><a href="https://tech-savvy.techidaily.com/optimizing-job-search-with-chatgpt-expertise/"><u>Optimizing Job Search with ChatGPT Expertise</u></a></li>
<li><a href="https://tech-savvy.techidaily.com/remedy-for-exceeded-chatgpt-limit-error-win/"><u>Remedy for Exceeded ChatGPT Limit Error (Win)</u></a></li>
<li><a href="https://tech-savvy.techidaily.com/simplify-ai-conversations-chromes-gpt-assistant-extension/"><u>Simplify AI Conversations: Chrome's GPT Assistant Extension</u></a></li>
<li><a href="https://tech-savvy.techidaily.com/startling-insight-initiate-conversations-with-gpt-3/"><u>Startling Insight: Initiate Conversations With GPT-3</u></a></li>
<li><a href="https://tech-savvy.techidaily.com/the-ethics-of-modifying-gpts-limits/"><u>The Ethics of Modifying GPT's Limits</u></a></li>
<li><a href="https://tech-savvy.techidaily.com/the-mythical-role-of-gpt-in-blockchain-strategies/"><u>The Mythical Role of GPT in Blockchain Strategies</u></a></li>
<li><a href="https://fox-http.techidaily.com/top-editing-apps-revolutionize-your-photo-backgrounds-for-2024/"><u>Top Editing Apps  Revolutionize Your Photo Backgrounds for 2024</u></a></li>
<li><a href="https://tech-haven.techidaily.com/unlockedchatgpt-subscription-deadline-clarity/"><u>UnlockedChatGPT: Subscription Deadline Clarity</u></a></li>
<li><a href="https://tech-savvy.techidaily.com/why-opt-for-claude-mastering-ai-to-power-your-vision/"><u>Why Opt for Claude? Mastering AI to Power Your Vision</u></a></li>
</ul></div>
